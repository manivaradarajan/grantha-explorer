# Refactoring the Grantha Data Pipeline

## Executive Summary

This document outlines a plan to refactor the data ingestion, processing, and publishing pipeline for the Grantha Explorer project. The current system, while functional for its initial purpose, tightly couples the data with the web application, uses a fragmented set of manual scripts, and lacks a robust, scalable architecture.

The proposed solution is to adopt a **two-repository architecture**:

1.  **`grantha-data`**: A new, dedicated repository to serve as the single source of truth for all textual content. It will manage the entire data processing workflow, from raw source ingestion to the publication of clean, link-rich JSON.
2.  **`grantha-explorer`**: The existing Next.js application, which will be refactored to become a pure data consumer, fetching its content from the `grantha-data` repository.

This refactor will result in a more scalable, maintainable, and automated system, enabling better data validation, the ability to serve multiple frontends, and a clear separation of concerns between content and presentation.

---

## 1. Current State Analysis

The existing data pipeline is contained entirely within the `grantha-explorer` repository.

-   **Single Repository:** All source texts (`granthas/`), processing scripts (`scripts/`), intermediate data (`public/data/`), and the Next.js application code reside in the same repository.
-   **Fragmented Tooling:** The workflow relies on a collection of standalone Python and TypeScript scripts. These scripts are run manually in a specific sequence to convert, validate, and index the data.
-   **Manual Indexing:** The final `granthas.json` file, which acts as the app's catalog, is generated by a script that indexes the content files present in the `public/data/library/` directory.
-   **Implicit Reference Handling:** Cross-reference links are represented as a custom `[display](ref:id/path)` Markdown format. The logic for parsing these links is handled entirely on the client-side within the Next.js application. The transformation from plain-text citations (e.g., `(bha. gī. 12.3)`) to this format is not currently automated.
-   **Limitations:**
    -   **Tight Coupling:** Changes to the data structure or processing logic risk breaking the application.
    -   **Lack of Scalability:** The manual, multi-script process is cumbersome and error-prone as the number of texts grows.
    -   **No Centralized Validation:** There is no automated way to ensure data integrity (e.g., non-destructive massaging) or link validity before publishing.
    -   **Poor Reusability:** The data is not easily consumable by other potential applications (e.g., a mobile app, research tools).

---

## 2. Proposed End State Architecture

### 2.1. Two-Repository Model

-   **`grantha-data` (New Repository):**
    -   **Purpose:** The canonical source and processing pipeline for all Grantha texts.
    -   **Output:** Versioned, structured JSON data, published as an NPM package.
-   **`grantha-explorer` (Existing Repository):**
    -   **Purpose:** A pure web application for presenting the data.
    -   **Data Source:** Consumes the NPM package published by `grantha-data`.

### 2.2. `grantha-data` Repository Details

This repository will be the core of the new data pipeline.

-   **Directory Structure:**
    ```
    grantha-data/
    ├── sources/         # Raw, original texts organized by category/collection
    ├── staged/          # Massaged, non-destructively edited Markdown files
    ├── published/       # Final, generated JSON output for different publications
    ├── scripts/         # All processing, validation, and publishing scripts
    ├── publications/    # Manifest files defining different build subsets
    └── package.json     # Orchestrates the entire pipeline via npm scripts
    ```
-   **Build System:** `npm` scripts will be used to orchestrate the entire build process, calling Python and TypeScript scripts as needed.
-   **Key Workflow Features:**
    1.  **Manifest-Driven Builds:** The `publications/` directory will contain JSON manifest files. Each manifest defines a specific build target (e.g., `visistadvaita-main`, `upanishads-only`), specifying which texts to include. This allows for the creation of multiple, distinct data sets from the same source.
    2.  **Automated Reference Transformation:** The build script will be responsible for converting plain-text citations into the required `[display](ref:id/path)` Markdown format. It will build a reference map dynamically for each publication, ensuring that links are only created for texts included in that specific build.
    3.  **Automated Validation:**
        -   **Pre-commit Hooks (`husky`):** A hook will run a validation script to ensure that the changes from `sources/` to `staged/` are non-destructive.
        -   **CI/CD (GitHub Actions):** Workflows will be created to run validation checks on every pull request and to automate the publishing process upon merging to the `main` branch.
    4.  **NPM Package Publishing:** The final output in the `published/` directory will be published as a versioned NPM package (e.g., `@grantha-explorer/data-visistadvaita-main`) to a registry like GitHub Packages or NPM.

### 2.3. `grantha-explorer` Repository Role

The application will be simplified to a pure data consumer.

-   **Dependency Management:** It will include the data package in its `package.json` dependencies.
-   **Data Loading:** All data-loading logic will be updated to read from `node_modules/@grantha-explorer/...` instead of its local `public/data/` directory.
-   **Decoupling:** All data processing scripts (`scripts/`), source files (`granthas/`), and raw data (`public/data/`) will be removed.

---

## 3. Phased Transition Plan

This transition is designed to be incremental, allowing for parallel development and minimizing disruption.

### Phase 1: `grantha-data` Repository Setup

1.  **Initialize Repository:** Create a new Git repository named `grantha-data`.
2.  **Scaffold Directories:** Create the initial directory structure: `sources/`, `staged/`, `scripts/`, `publications/`.
3.  **Initialize `npm`:** Run `npm init` and set up a basic `package.json` to manage scripts and dependencies.

### Phase 2: Data and Script Migration

1.  **Move Source Files:** Copy the contents of `grantha-explorer/granthas/` into `grantha-data/sources/`. Reorganize the files according to the new hierarchical structure (e.g., `sruti/upanishad/...`).
2.  **Move Scripts:** Migrate all data-related processing scripts from `grantha-explorer/scripts/` to `grantha-data/scripts/`.
3.  **Migrate Metadata:** Move `granthas-meta.json` and `granthas-order.json` into the `grantha-data` repository to be used as source material for the new build process.
4.  **Checkpoint:** At this stage, the `grantha-explorer` app remains fully functional. The new repository is being prepared offline.

### Phase 3: Develop the New Build Pipeline

1.  **Orchestrate Scripts:** In `grantha-data`, create `npm` scripts in `package.json` to chain the existing Python and TypeScript scripts into a single `npm run build` command.
2.  **Implement Reference Parsing:** Enhance the build script to perform the transformation of plain-text references into the `ref:` protocol Markdown links.
3.  **Implement Manifest Builds:** Refactor the build script to be driven by manifest files from the `publications/` directory. The script should accept a publication name as an argument and generate output in a corresponding subdirectory within `published/`.
4.  **Goal:** The output of `npm run build -- --publication main` in `grantha-data` should produce JSON files that are structurally identical to the ones currently in `grantha-explorer/public/data/library/`.

### Phase 4: Integrate `grantha-explorer` with the New Pipeline

1.  **Local Linking:** Use `npm link` to make the local `grantha-data` repository available as a node module to the `grantha-explorer` repository. This allows for rapid testing without publishing anything.
2.  **Refactor Data Loading:** In `grantha-explorer`, modify all file paths that point to `public/data/` to instead point to the linked module (e.g., `require('@grantha-explorer/data/published/main/...')`).
3.  **Test:** Thoroughly test the application to ensure that all data loads and renders correctly. All functionality, including internal and external reference links, should work as before.

### Phase 5: Final Cleanup and Automation

1.  **Publish Package:** Publish the first official version of the data package from `grantha-data` to GitHub Packages or NPM.
2.  **Update Dependency:** In `grantha-explorer`, replace the `npm link` dependency with the newly published package version in `package.json`.
3.  **Remove Old Assets:** Delete the `granthas/`, `scripts/`, and `public/data/` directories from the `grantha-explorer` repository to complete the separation.
4.  **Automate `grantha-data`:** Implement the GitHub Action workflows for validation on pull requests and automated publishing on merges to the `main` branch.
